{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "env_loaded = load_dotenv()\n",
    "env_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "import os\n",
    "\n",
    "# azure_deployment = \"gpt-4o-mini\"\n",
    "azure_deployment = \"gpt-4o\"\n",
    "\n",
    "postgres_host = os.getenv(\"POSTGRES_HOST\")\n",
    "postgres_port = os.getenv(\"POSTGRES_PORT\")\n",
    "postgres_user = os.getenv(\"POSTGRES_USER\")\n",
    "postgres_db = os.getenv(\"POSTGRES_DB\")\n",
    "postgres_password = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "\n",
    "connection = f\"postgresql+psycopg://{postgres_user}:{postgres_password}@{postgres_host}:{postgres_port}/{postgres_db}\"\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=azure_deployment,\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    temperature=0,\n",
    "    max_tokens=8192,\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tools Definition\n",
    "\n",
    "from typing import List\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import inspect, MetaData\n",
    "from typing import Dict\n",
    "\n",
    "schema_info_str = None\n",
    "\n",
    "def get_database_schema() -> str:\n",
    "    \"\"\"\n",
    "    Query the PostgreSQL database and return a formatted string containing all tables\n",
    "    and their columns with data types.\n",
    "    \"\"\"\n",
    "    global schema_info_str  # Declare as global to modify it\n",
    "\n",
    "    if schema_info_str:\n",
    "        return schema_info_str\n",
    "    else:\n",
    "        try:\n",
    "            # Create engine\n",
    "            engine = sa.create_engine(connection)\n",
    "            inspector = inspect(engine)\n",
    "\n",
    "            # Get all table names\n",
    "            tables = inspector.get_table_names()\n",
    "\n",
    "            if not tables:\n",
    "                return \"No tables found in the database.\"\n",
    "\n",
    "            # Build formatted output\n",
    "            schema_info = [\"Database Schema:\"]\n",
    "            schema_info.append(\"=\" * 50)\n",
    "\n",
    "            for table in tables:\n",
    "                schema_info.append(f\"\\nTable: {table}\")\n",
    "                schema_info.append(\"-\" * 30)\n",
    "\n",
    "                # Get columns for each table\n",
    "                columns = inspector.get_columns(table)\n",
    "                for column in columns:\n",
    "                    col_name = column[\"name\"]\n",
    "                    col_type = str(column[\"type\"])\n",
    "                    nullable = \"NULL\" if column.get(\"nullable\", True) else \"NOT NULL\"\n",
    "                    primary_key = inspector.get_pk_constraint(table)\n",
    "                    is_pk = (\n",
    "                        \"PRIMARY KEY\"\n",
    "                        if col_name in primary_key[\"constrained_columns\"]\n",
    "                        else \"\"\n",
    "                    )\n",
    "\n",
    "                    schema_info.append(\n",
    "                        f\"  - {col_name}: {col_type} {nullable} {is_pk}\".rstrip()\n",
    "                    )\n",
    "\n",
    "            schema_info_str = \"\\n\".join(schema_info)\n",
    "            return schema_info_str\n",
    "        except Exception as e:\n",
    "            return f\"Error retrieving database schema: {str(e)}\"\n",
    "\n",
    "\n",
    "def execute_sql_query(sql_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute a SQL query and return the results in a formatted string.\n",
    "\n",
    "    Args:\n",
    "        sql_query (str): The SQL query to execute\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted string containing the query results or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create engine\n",
    "        engine = sa.create_engine(connection)\n",
    "\n",
    "        # Execute query and fetch results\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(sa.text(sql_query))\n",
    "\n",
    "            # Get column names\n",
    "            columns = result.keys()\n",
    "\n",
    "            # Fetch all rows\n",
    "            rows = result.fetchall()\n",
    "\n",
    "            if not rows:\n",
    "                return \"Query executed successfully. No results returned.\"\n",
    "\n",
    "            # Calculate column widths\n",
    "            col_widths = {col: len(str(col)) for col in columns}\n",
    "            for row in rows:\n",
    "                for col, value in zip(columns, row):\n",
    "                    col_widths[col] = max(col_widths[col], len(str(value)))\n",
    "\n",
    "            # Format the output\n",
    "            output = []\n",
    "\n",
    "            # Create header\n",
    "            header = \" | \".join(str(col).ljust(col_widths[col]) for col in columns)\n",
    "            output.append(header)\n",
    "\n",
    "            # Add separator\n",
    "            separator = \"-\" * len(header)\n",
    "            output.append(separator)\n",
    "\n",
    "            # Add rows\n",
    "            for row in rows:\n",
    "                formatted_row = \" | \".join(\n",
    "                    str(value).ljust(col_widths[col])\n",
    "                    for col, value in zip(columns, row)\n",
    "                )\n",
    "                output.append(formatted_row)\n",
    "\n",
    "            # Add result count\n",
    "            output.append(f\"\\n{len(rows)} rows returned.\")\n",
    "\n",
    "            return \"\\n\".join(output)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error executing query: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [execute_sql_query]\n",
    "model_with_tools = model.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "class State(MessagesState):\n",
    "    pass\n",
    "\n",
    "SYSTEM_MESSAGE_PROMPT = \"\"\"You are a database expert assistant who can interpret the user queries and provide a helpful response.\n",
    "\n",
    "Use the provided toolset efficiently to generate helpful response for the user.\n",
    "\"\"\"\n",
    "\n",
    "sys_msg = SystemMessage(content=SYSTEM_MESSAGE_PROMPT)\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [model_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_info_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"List all the tables in my database grouped by schema, do not include system related schema and tables.\")})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
