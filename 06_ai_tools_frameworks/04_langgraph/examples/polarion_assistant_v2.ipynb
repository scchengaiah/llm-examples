{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "env_loaded = load_dotenv()\n",
    "env_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "import os\n",
    "\n",
    "azure_deployment = \"gpt-4o\"\n",
    "\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=azure_deployment,\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    temperature=0,\n",
    "    max_tokens=8192,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "API_URL = \"http://192.168.80.162/polarion/rest/v1/projects/ajmal_Training/workitems\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('POLARION_ACCESS_TOKEN')}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_current_datetime():\n",
    "    \"\"\"\n",
    "    Returns the current date and time.\n",
    "\n",
    "    :return: A string representing the current date and time in the format YYYY-MM-DD HH:MM:SS.\n",
    "    \"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def extract_workitems_from_polarion(lucene_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch workitems based on the provided lucene query.\n",
    "\n",
    "    Args:\n",
    "        lucene_query (str): Lucene query that retrieves the relevant work items.\n",
    "\n",
    "    Returns:\n",
    "        str: Markdown-formatted table containing work item details\n",
    "    \"\"\"\n",
    "    try:\n",
    "        params = {\"query\": lucene_query, \"fields[workitems]\": \"@all\"}\n",
    "        # Make API request\n",
    "        response = requests.get(API_URL, headers=headers, params=params)\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "\n",
    "        # Parse response JSON\n",
    "        json_data = response.json()\n",
    "\n",
    "        # Extract work items details\n",
    "        if \"data\" in json_data and isinstance(json_data[\"data\"], list):\n",
    "            # Prepare markdown table\n",
    "            table_header = \"| ID | Title | Description |\\n|---|---|---|\\n\"\n",
    "            table_rows = []\n",
    "\n",
    "            for item in json_data[\"data\"]:\n",
    "                # Extract ID\n",
    "                work_item_id = item.get(\"id\", \"\")\n",
    "\n",
    "                # Extract attributes (title and description)\n",
    "                attributes = item.get(\"attributes\", {})\n",
    "                title = attributes.get(\"title\", \"\")\n",
    "                description = attributes.get(\"description\", \"\")\n",
    "\n",
    "                # Escape special markdown characters\n",
    "                if title:\n",
    "                    title = title.replace(\"|\", \"\\\\|\")\n",
    "                if description:\n",
    "                    description = description[\"value\"].replace(\"|\", \"\\\\|\")\n",
    "\n",
    "                # Create table row\n",
    "                if work_item_id:\n",
    "                    table_row = f\"| {work_item_id} | {title} | {description} |\\n\"\n",
    "                    table_rows.append(table_row)\n",
    "\n",
    "            # Combine header and rows\n",
    "            if table_rows:\n",
    "                formatted_output = (\n",
    "                    f\"PORTAL_URL: {json_data['links']['portal']}\\n\\n\"\n",
    "                    + table_header\n",
    "                    + \"\".join(table_rows)\n",
    "                )\n",
    "                return formatted_output\n",
    "            else:\n",
    "                return \"No work items found in the response\"\n",
    "        else:\n",
    "            return \"Invalid response format: 'data' array not found\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"API request failed: {str(e)}\"\n",
    "    except (KeyError, TypeError) as e:\n",
    "        return f\"Error parsing response: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Unexpected error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = extract_workitems_from_polarion(\n",
    "    \"type:systemrequirement AND created:[20250115 TO 20250130]\"\n",
    ")\n",
    "\n",
    "print(result)\n",
    "\n",
    "extract_workitems_from_polarion(\n",
    "    \"type:systemrequirement AND created:[20250115 TO 20250130]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert in interpreting user queries and generates helpful response based on the configured rules.\n",
    "\n",
    "\n",
    "## Polarion supported object types:\n",
    "\n",
    "| ID | NAME |\n",
    "|----|------|\n",
    "| systemrequirement | System Requirement |\n",
    "| systemtestcase | System Test Case |\n",
    "| softwarerequirement | Software Requirement |\n",
    "| softwaretestcase | Software Test Case |\n",
    "| risk | Risk |\n",
    "| release | Release |\n",
    "| workpackage | Work Package |\n",
    "| task | Task |\n",
    "| changerequest | Change Request |\n",
    "| issue | Issue |\n",
    "| testcase | Test Case |\n",
    "| unittestcase | Unit Test Case |\n",
    "| question | Question |\n",
    "| systemTestCase1 | System Test Case 1 |\n",
    "| systemRequirment1 | System Requirement 1 |\n",
    "| new_wl_type | New Custom Type |\n",
    "\n",
    "## Rules:\n",
    "\n",
    "1. Understand the user query and if it is related to Polarion application data extraction, generate appropriate lucene query and use provided tools to fetch data.\n",
    "2. From the provided Polarion object types, use values under ID column to formulate Lucene query based on user question. The NAME column is for your reference to interpret the user question.\n",
    "3. If the user intent is to extract data that is not part of the provided object types, inform the user politely about the same.\n",
    "4. If the user query is related to Polarion Application, then you are allowed to respond in that context. ALL OTHER queries should be politely rejected.\n",
    "5. PORTAL_URL is for overall data and do not link it to a particular extracted data.\n",
    "\n",
    "## Here are some of the examples for Lucene query for your understanding:\n",
    "\n",
    "Example 1:\n",
    "If user gives *Human Readable Query*: \"Show all Task Workitems Assign to me\"\n",
    "and *UserId*: \"458963\"  then you should generate like *Lucene Query*: \"type:task AND assignee.id:458963\"\n",
    "\n",
    "Example 2:\n",
    "*Human Readable Query*: \"Render Software Workitems that have specific comment\"\n",
    "*Lucene Query*: \"type:softwarerequirement AND HAS_VALUE:comments.text\"\n",
    "\n",
    "Example 3:\n",
    "*Human Readable Query*: \"Display the Workitems which have Initial Estimate 1Day And Time Spent on a workitem should be 9h\"\n",
    "*Lucene Query*: \"initialEstimate:1d AND timeSpent:9h\"\n",
    "\n",
    "Example 4:\n",
    "*Human Readable Query*: \"How to get workitems of type task & voice with open status\"\n",
    "*Lucene Query*: \"type:(task voice) AND status:open\"\n",
    "\n",
    "Example 5:\n",
    "*Human Readable Query*: \"Show all Workitems created from 10-july-2024 to 30-Aug-2024\"\n",
    "*Lucene Query*: \"created:[20240710 TO 20240830]\"\n",
    "\n",
    "Example 6:\n",
    "*Human Readable Query*: \"Filter Workitems based on Must Have Severity\"\n",
    "*Lucene Query*: \"severity:must_have\"\n",
    "\n",
    "Example 7:\n",
    "*Human Readable Query*: \"Workitem which is assigned to me and status open and priority medium\"\n",
    "*Lucene Query*: \"assignee.id:UserId AND status:open AND priority:medium\"\n",
    "\n",
    "Example 8:\n",
    "*Human Readable Query*: \"Workitem which are not assigned to me and status open and priority medium\"\n",
    "*Lucene Query*: \"-assignee.id:UserId AND status:open AND priority:medium\"  do not mention negative for the not mention please\n",
    "\n",
    "## Response format:\n",
    "\n",
    "Format your response in a neat well-structured markdown format.\n",
    "\n",
    "## Example Response:\n",
    "\n",
    "Here are the extracted work items:\n",
    "\n",
    "workitem-5897\n",
    "workitem-5693\n",
    "worktitem-5869\n",
    "\n",
    "You can view the extracted work items on the Polarion portal using this [link](PORTAL_URL)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "sys_msg = SystemMessage(content=SYSTEM_PROMPT)\n",
    "tools = [extract_workitems_from_polarion, get_current_datetime]\n",
    "model_with_tools = model.bind_tools(tools, parallel_tool_calls=False)\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [model_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"Extract all system requirments created on 28-JAn-2025\")]\n",
    "# messages = [HumanMessage(\"How do I create LiveDocs ?\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\": messages})\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
