{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of a multi-agent workflow, I would like to build an application that can handle questions from various domains. We will have a set of expert agents, each specializing in different types of questions, and a router agent that will find the best-suited expert to address each query. Such an application has numerous potential use cases: from automating customer support to answering questions from colleagues in internal chats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create the agent state — the information that will help agents to solve the question together. I will use the following fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question — initial customer request.\n",
    "\n",
    "question_type — the category that defines which agent will be working on the request.\n",
    "\n",
    "answer — the proposed answer to the question.\n",
    "\n",
    "feedback — a field for future use that will gather some feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don’t use any reducers, so our state will store only the latest version of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "class MultiAgentState(TypedDict):\n",
    "    question: str\n",
    "    question_type: str\n",
    "    answer: str\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_loaded = load_dotenv()\n",
    "print(f\"Env loaded: {env_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global connection object (initialized by helper function)\n",
    "_conn = None\n",
    "\n",
    "\n",
    "def _get_db_connection():\n",
    "    \"\"\"Helper function to get a database connection.\"\"\"\n",
    "    global _conn\n",
    "    db_host = os.environ.get(\"POSTGRES_HOST\")\n",
    "    db_user = os.environ.get(\"POSTGRES_USER\")\n",
    "    db_password = os.environ.get(\"POSTGRES_PASSWORD\")\n",
    "    db_name = os.environ.get(\"POSTGRES_DB\")\n",
    "    db_port = os.environ.get(\"POSTGRES_PORT\")\n",
    "\n",
    "    connection_string = (\n",
    "        f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "    )\n",
    "    print(connection_string)\n",
    "    if _conn is None or _conn.closed:\n",
    "        try:\n",
    "            _conn = psycopg.connect(connection_string)\n",
    "            _conn.autocommit = False  # Set autocommit to False for more control\n",
    "        except (Exception, psycopg.Error) as error:\n",
    "            print(traceback.format_exc())\n",
    "            raise Exception(f\"Error connecting to database: {error}\")\n",
    "\n",
    "    return _conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_data(query):\n",
    "    \"\"\"\n",
    "    Executes the SQL query passed as an argument and returns the data from\n",
    "    Postgresql database in nicely formatted textual format.\n",
    "\n",
    "    Args:\n",
    "        query (str): The SQL query to execute.\n",
    "\n",
    "    Returns:\n",
    "        str: A nicely formatted string representation of the data returned\n",
    "             by the query.\n",
    "             Returns \"Error: No results found\" if the query returns no data or\n",
    "             an error message if an exception occurs.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = _get_db_connection()\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(query)\n",
    "        rows = cur.fetchall()\n",
    "\n",
    "        if not rows:\n",
    "            return \"Error: No results found\"\n",
    "\n",
    "        # Get column names for headers\n",
    "        column_names = [desc[0] for desc in cur.description]\n",
    "\n",
    "        # Format data with headers\n",
    "        formatted_data = \"\"\n",
    "\n",
    "        # Calculate maximum width for each column\n",
    "        max_widths = [len(str(col)) for col in column_names]\n",
    "        for row in rows:\n",
    "            for i, value in enumerate(row):\n",
    "                max_widths[i] = max(max_widths[i], len(str(value)))\n",
    "\n",
    "        # Create header line\n",
    "        header_line = \"|\"\n",
    "        for i, col in enumerate(column_names):\n",
    "            header_line += f\" {col.ljust(max_widths[i])} |\"\n",
    "        formatted_data += header_line + \"\\n\"\n",
    "\n",
    "        # Create separator line\n",
    "        separator_line = \"|\"\n",
    "        for width in max_widths:\n",
    "            separator_line += f\"-{'-'*width}-|\"\n",
    "        formatted_data += separator_line + \"\\n\"\n",
    "\n",
    "        # Create data lines\n",
    "        for row in rows:\n",
    "            row_line = \"|\"\n",
    "            for i, value in enumerate(row):\n",
    "                row_line += f\" {str(value).ljust(max_widths[i])} |\"\n",
    "            formatted_data += row_line + \"\\n\"\n",
    "\n",
    "        cur.close()\n",
    "        return formatted_data\n",
    "\n",
    "    except (Exception, psycopg.Error) as error:\n",
    "        return f\"Database returned error: {error}\"\n",
    "    finally:\n",
    "        if conn:  # if connection was established\n",
    "            # Do not close the global connection object\n",
    "            # conn.close()\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class SQLQuery(BaseModel):\n",
    "    query: str = Field(description=\"SQL query to execute\")\n",
    "\n",
    "\n",
    "@tool(args_schema=SQLQuery)\n",
    "def execute_sql(query: str) -> str:\n",
    "    \"\"\"Returns the result of SQL query execution\"\"\"\n",
    "    return get_sql_data(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let’s create a router node. It will be a simple LLM model that defines the category of question (database, LangChain or general questions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    temperature=0,\n",
    "    max_tokens=8192,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "question_category_prompt = \"\"\"You are a senior specialist of analytical support. Your task is to classify the incoming questions. \n",
    "Depending on your answer, question will be routed to the right team, so your task is crucial for our team. \n",
    "There are 3 possible question types: \n",
    "- DATABASE - questions related to our database (tables or fields)\n",
    "- LANGCHAIN- questions related to LangGraph or LangChain libraries\n",
    "- GENERAL - general questions\n",
    "Return in the output only one word (DATABASE, LANGCHAIN or  GENERAL).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def router_node(state: MultiAgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=question_category_prompt),\n",
    "        HumanMessage(content=state[\"question\"]),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"question_type\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our first node — the router — let’s build a simple graph to test the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "builder = StateGraph(MultiAgentState)\n",
    "builder.add_node(\"router\", router_node)\n",
    "\n",
    "builder.set_entry_point(\"router\")\n",
    "builder.add_edge(\"router\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s test our workflow with different types of questions to see how it performs in action. This will help us evaluate whether the router agent correctly assigns questions to the appropriate expert agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain based question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"question\": \"Does LangChain support Ollama?\",\n",
    "    },\n",
    "    thread,\n",
    "):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database Related question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"question\": \"What info do we have in airflow_test.dag_runs table?\",\n",
    "    },\n",
    "    thread,\n",
    "):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"question\": \"How are you?\",\n",
    "    },\n",
    "    thread,\n",
    "):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommend to build complex graphs incrementally and test each step independently. With such an approach, one can ensure that each iteration works expectedly and can save you a significant amount of debugging time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s create nodes for our expert agents. We will use the ReAct agent with the SQL tool we previously built as the database agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# database expert\n",
    "sql_expert_system_prompt = '''\n",
    "You are an expert in SQL, so you can help the team \n",
    "to gather needed data to power their decisions. \n",
    "You are very accurate and take into account all the nuances in data. \n",
    "You use SQL to get the data before answering the question.\n",
    "'''\n",
    "\n",
    "def sql_expert_node(state: MultiAgentState):\n",
    "    sql_agent = create_react_agent(model, [execute_sql],\n",
    "        state_modifier = sql_expert_system_prompt)\n",
    "    messages = [HumanMessage(content=state['question'])]\n",
    "    result = sql_agent.invoke({\"messages\": messages})\n",
    "    return {'answer': result['messages'][-1].content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "search_run_tool = DuckDuckGoSearchResults()\n",
    "\n",
    "search_expert_system_prompt = \"\"\"\n",
    "You are an expert in LangChain and other technologies. \n",
    "Your goal is to answer questions based on results provided by search.\n",
    "You don't add anything yourself and provide only information baked by other sources. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def search_expert_node(state: MultiAgentState):\n",
    "    sql_agent = create_react_agent(\n",
    "        model, [search_run_tool], state_modifier=search_expert_system_prompt\n",
    "    )\n",
    "    messages = [HumanMessage(content=state[\"question\"])]\n",
    "    result = sql_agent.invoke({\"messages\": messages})\n",
    "    return {\"answer\": result[\"messages\"][-1].content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For general questions, we will leverage a simple LLM model without specific tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general model\n",
    "general_prompt = \"\"\"You're a friendly assistant and your goal is to answer general questions.\n",
    "Please, don't provide any unchecked information and just tell that you don't know if you don't have enough info.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def general_assistant_node(state: MultiAgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=general_prompt),\n",
    "        HumanMessage(content=state[\"question\"]),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last missing bit is a conditional function for routing. This will be quite straightforward—we just need to propagate the question type from the state defined by the router node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state: MultiAgentState):\n",
    "    return state[\"question_type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it’s time to create our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MultiAgentState)\n",
    "builder.add_node(\"router\", router_node)\n",
    "builder.add_node(\"database_expert\", sql_expert_node)\n",
    "builder.add_node(\"langchain_expert\", search_expert_node)\n",
    "builder.add_node(\"general_assistant\", general_assistant_node)\n",
    "builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"DATABASE\": \"database_expert\",\n",
    "        \"LANGCHAIN\": \"langchain_expert\",\n",
    "        \"GENERAL\": \"general_assistant\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "builder.set_entry_point(\"router\")\n",
    "builder.add_edge(\"database_expert\", END)\n",
    "builder.add_edge(\"langchain_expert\", END)\n",
    "builder.add_edge(\"general_assistant\", END)\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can test the setup on a couple of questions to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "results = []\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"question\": \"What info do we have in airflow_test.dag_runs table?\",\n",
    "    },\n",
    "    thread\n",
    "):\n",
    "    print(s)\n",
    "    results.append(s)\n",
    "print(results[-1][\"database_expert\"][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! It gives a relevant result for the database-related question. Let’s try asking about LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"42\"}}\n",
    "results = []\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"question\": \"Can you provide an example for LCEL ?\",\n",
    "    },\n",
    "    thread,\n",
    "):\n",
    "    print(s)\n",
    "    results.append(s)\n",
    "\n",
    "print(results[-1][\"langchain_expert\"][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding human-in-the-loop interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve done an excellent job creating a tool to answer questions. However, in many cases, it’s beneficial to keep a human in the loop to approve proposed actions or provide additional feedback. Let’s add a step where we can collect feedback from a human before returning the final result to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest approach is to add two additional nodes:\n",
    "\n",
    "- A human node to gather feedback,\n",
    "- An editor node to revisit the answer, taking into account the feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create these nodes:\n",
    "\n",
    "- Human node: This will be a dummy node, and it won’t perform any actions.\n",
    "- Editor node: This will be an LLM model that receives all the relevant information (customer question, draft answer and provided feedback) and revises the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback_node(state: MultiAgentState):\n",
    "    pass\n",
    "\n",
    "editor_prompt = '''You're an editor and your goal is to provide the final answer to the customer, taking into account the feedback. \n",
    "You don't add any information on your own. You use friendly and professional tone.\n",
    "In the output please provide the final answer to the customer without additional comments.\n",
    "Here's all the information you need.\n",
    "\n",
    "Question from customer: \n",
    "----\n",
    "{question}\n",
    "----\n",
    "Draft answer:\n",
    "----\n",
    "{answer}\n",
    "----\n",
    "Feedback: \n",
    "----\n",
    "{feedback}\n",
    "----\n",
    "'''\n",
    "\n",
    "def editor_node(state: MultiAgentState):\n",
    "  messages = [\n",
    "    SystemMessage(content=editor_prompt.format(question = state['question'], answer = state['answer'], feedback = state['feedback']))\n",
    "  ]\n",
    "  response = model.invoke(messages)\n",
    "  return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s add these nodes to our graph. Additionally, we need to introduce an interruption before the human node to ensure that the process pauses for human feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MultiAgentState)\n",
    "builder.add_node(\"router\", router_node)\n",
    "builder.add_node(\"database_expert\", sql_expert_node)\n",
    "builder.add_node(\"langchain_expert\", search_expert_node)\n",
    "builder.add_node(\"general_assistant\", general_assistant_node)\n",
    "builder.add_node(\"human\", human_feedback_node)\n",
    "builder.add_node(\"editor\", editor_node)\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"DATABASE\": \"database_expert\",\n",
    "        \"LANGCHAIN\": \"langchain_expert\",\n",
    "        \"GENERAL\": \"general_assistant\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "builder.set_entry_point(\"router\")\n",
    "\n",
    "builder.add_edge(\"database_expert\", \"human\")\n",
    "builder.add_edge(\"langchain_expert\", \"human\")\n",
    "builder.add_edge(\"general_assistant\", \"human\")\n",
    "builder.add_edge(\"human\", \"editor\")\n",
    "builder.add_edge(\"editor\", END)\n",
    "graph = builder.compile(checkpointer=memory, interrupt_before=[\"human\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we run the graph, the execution will be stopped before the human node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "for event in graph.stream(\n",
    "    {\n",
    "        \"question\": \"What are the types of fields airflow_test.dag_runs table?\",\n",
    "    },\n",
    "    thread,\n",
    "):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s get the customer input and update the state with the feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"Do I need to change anything in the answer?\")\n",
    "\n",
    "# Do I need to change anything in the answer?\n",
    "# It looks wonderful. Could you only make it a bit friendlier please?\n",
    "\n",
    "graph.update_state(thread, {\"feedback\": user_input}, as_node=\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the state to confirm that the feedback has been populated and that the next node in the sequence is editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.get_state(thread).values['feedback'])\n",
    "\n",
    "print(graph.get_state(thread).next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just continue the execution. Passing None as input will resume the process from the point where it was paused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    print(event)\n",
    "\n",
    "print(event[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement human-in-the-loop interactions in a more agentic way by equipping our editor with the [Human](https://python.langchain.com/v0.2/docs/integrations/tools/human_tools/) tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import HumanInputRun\n",
    "\n",
    "human_tool = HumanInputRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"question\": \"What are the types of fields in ecommerce_db.users table?\",\n",
    "    \"answer\": \"The `ecommerce_db.users` table has the following fields:\\n\\n1. **user_id**: UInt64\\n2. **country**: String\\n3. **is_active**: UInt8\\n4. **age**: UInt64\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_agent_prompt = \"\"\"You're an editor and your goal is to provide the final answer to the customer, taking into the initial question.\n",
    "If you need any clarifications or need feedback, please, use human. Always reach out to human to get the feedback before final answer.\n",
    "You don't add any information on your own. You use friendly and professional tone. \n",
    "In the output please provide the final answer to the customer without additional comments.\n",
    "Here's all the information you need.\n",
    "\n",
    "Question from customer: \n",
    "----\n",
    "{question}\n",
    "----\n",
    "Draft answer:\n",
    "----\n",
    "{answer}\n",
    "----\n",
    "\"\"\"\n",
    "\n",
    "editor_agent = create_react_agent(model, [human_tool])\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=editor_agent_prompt.format(\n",
    "            question=state[\"question\"], answer=state[\"answer\"]\n",
    "        )\n",
    "    )\n",
    "]\n",
    "editor_result = editor_agent.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(editor_result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editor_agent_node(state: MultiAgentState):\n",
    "    editor_agent = create_react_agent(model, [human_tool])\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=editor_agent_prompt.format(\n",
    "                question=state[\"question\"], answer=state[\"answer\"]\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    result = editor_agent.invoke({\"messages\": messages})\n",
    "    return {\"answer\": result[\"messages\"][-1].content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MultiAgentState)\n",
    "builder.add_node(\"router\", router_node)\n",
    "builder.add_node(\"database_expert\", sql_expert_node)\n",
    "builder.add_node(\"langchain_expert\", search_expert_node)\n",
    "builder.add_node(\"general_assistant\", general_assistant_node)\n",
    "builder.add_node(\"editor\", editor_agent_node)\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"DATABASE\": \"database_expert\",\n",
    "        \"LANGCHAIN\": \"langchain_expert\",\n",
    "        \"GENERAL\": \"general_assistant\",\n",
    "    },\n",
    ")\n",
    "\n",
    "builder.set_entry_point(\"router\")\n",
    "\n",
    "builder.add_edge(\"database_expert\", \"editor\")\n",
    "builder.add_edge(\"langchain_expert\", \"editor\")\n",
    "builder.add_edge(\"general_assistant\", \"editor\")\n",
    "builder.add_edge(\"editor\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"42\"}}\n",
    "results = []\n",
    "\n",
    "for event in graph.stream(\n",
    "    {\n",
    "        \"question\": \"What are the types of fields in airflow_test.dag_runs table?\",\n",
    "    },\n",
    "    thread,\n",
    "):\n",
    "    print(event)\n",
    "    results.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
