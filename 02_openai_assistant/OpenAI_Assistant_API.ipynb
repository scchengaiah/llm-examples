{"cells":[{"cell_type":"markdown","id":"8218f4d5-e872-4841-bf3e-d74fd610d647","metadata":{},"source":["# OpenAI Assistants API tutorial "]},{"cell_type":"markdown","id":"ea6e8163","metadata":{},"source":["https://www.datacamp.com/tutorial/open-ai-assistants-api-tutorial\n","\n","**Azure Assistant Reference:**  \n","\n","Retrieval feature was not available when exploring since it was in a preview release.\n","\n","https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant\n","\n","**OpenAI Assistant Reference:**\n","\n","https://platform.openai.com/docs/assistants/overview\n","\n","> Note that the below code is modified based on the latest update of the Assistant API from OpenAI"]},{"cell_type":"markdown","id":"045f9bd1-0764-41ae-9176-f3d913f2402d","metadata":{},"source":["## Import relevant libraries"]},{"cell_type":"code","execution_count":null,"id":"57490a47-f8f8-4f71-9ec2-e9e2fef2891b","metadata":{"executionCancelledAt":null,"executionTime":5888,"lastExecutedAt":1701963085467,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install --upgrade openai","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"outputs":[],"source":["!pip install --upgrade openai"]},{"cell_type":"code","execution_count":null,"id":"61bf6f47","metadata":{},"outputs":[],"source":["from dotenv import load_dotenv\n","load_dotenv()"]},{"cell_type":"code","execution_count":null,"id":"567c6676-65ae-433d-ab5b-e11e31834497","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1701963652342,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import os \nfrom openai import OpenAI "},"outputs":[],"source":["import os \n","from openai import OpenAI"]},{"cell_type":"markdown","id":"3eb56a35-16ea-4540-8066-d94e396a44ba","metadata":{},"source":["## Environment configuration"]},{"cell_type":"code","execution_count":null,"id":"74afbfb0-b729-446b-9116-8172396ae5b0","metadata":{"executionCancelledAt":null,"executionTime":15,"lastExecutedAt":1701963657898,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"client = OpenAI()"},"outputs":[],"source":["client = OpenAI()"]},{"cell_type":"markdown","id":"241fdb5c","metadata":{},"source":["Test client by asking a sample question."]},{"cell_type":"code","execution_count":null,"id":"1b541870","metadata":{},"outputs":[],"source":["message_text = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},\n","                {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}]\n","\n","completion = client.chat.completions.create(\n","  model=\"gpt-4o\",\n","  messages = message_text,\n","  temperature=0.7,\n","  max_tokens=100,\n","  top_p=0.95,\n","  frequency_penalty=0,\n","  presence_penalty=0,\n","  stop=None\n",")\n","\n","completion.choices[0].message.content"]},{"cell_type":"markdown","id":"9ae93e3d-4d46-477e-9ccd-38951aba56c1","metadata":{},"source":["## Assistant Creation"]},{"cell_type":"markdown","id":"a43646f0","metadata":{},"source":["### [Step 1: Create a new Assistant with File Search Enabled](https://platform.openai.com/docs/assistants/tools/file-search/step-1-create-a-new-assistant-with-file-search-enabled)"]},{"cell_type":"code","execution_count":null,"id":"68d30bb6-7a28-434b-afcb-6d10f2072f3d","metadata":{"executionCancelledAt":null,"executionTime":2877,"lastExecutedAt":1701967219954,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create the assistant\ninst=\"You are a polite and expert knowledge retrieval assistant. Use the documents provided as a knowledge base to answer questions\"\nassistant_name=\"Scientific Paper Assistant\"\n\nmy_assistant = create_assistant(assistant_name, inst, uploaded_file)"},"outputs":[],"source":["# Create the assistant\n","\n","assistant = client.beta.assistants.create(\n","  name=\"Scientific Paper Assistant\",\n","  instructions=\"You are a polite and expert knowledge retrieval assistant. Use the documents provided as a knowledge base to answer questions.\",\n","  model=\"gpt-4o\",\n","  tools=[{\"type\": \"file_search\"}],\n",")"]},{"cell_type":"markdown","id":"f4e8ac1e-c005-42f5-aaf9-2ad4c4262470","metadata":{},"source":["## File Upload"]},{"cell_type":"markdown","id":"49218a2b","metadata":{},"source":["### [Step 2: Upload files and add them to a Vector Store](https://platform.openai.com/docs/assistants/tools/file-search/step-2-upload-files-and-add-them-to-a-vector-store)"]},{"cell_type":"markdown","id":"139d404e","metadata":{},"source":["Create a vector store object to hold the file."]},{"cell_type":"code","execution_count":null,"id":"b7649294","metadata":{},"outputs":[],"source":["# Create a vector store called \"OpenAI Assistants Exploration\"\n","vector_store = client.beta.vector_stores.create(name=\"OpenAI Assistants Exploration\")"]},{"cell_type":"markdown","id":"4371a4d8","metadata":{},"source":["Prepare the files to upload"]},{"cell_type":"code","execution_count":null,"id":"18623b73","metadata":{},"outputs":[],"source":["# Ready the files for upload to OpenAI\n","file_paths = [\"data/transformer_paper.pdf\"]\n","file_streams = [open(path, \"rb\") for path in file_paths]"]},{"cell_type":"markdown","id":"08ae6b25","metadata":{},"source":["Upload the files to the vector store as batches"]},{"cell_type":"code","execution_count":null,"id":"8b601d60","metadata":{},"outputs":[],"source":["# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n","# and poll the status of the file batch for completion.\n","file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n","  vector_store_id=vector_store.id, files=file_streams\n",")\n"," \n","# You can print the status and the file counts of the batch to see the result of this operation.\n","print(file_batch.status)\n","print(file_batch.file_counts)"]},{"cell_type":"markdown","id":"a25bc816","metadata":{},"source":["Update the assistant to include the created vector store for retrieval purpose."]},{"cell_type":"markdown","id":"55c081fd","metadata":{},"source":["### [Step 3: Update the assistant to to use the new Vector Store](https://platform.openai.com/docs/assistants/tools/file-search/step-3-update-the-assistant-to-to-use-the-new-vector-store)"]},{"cell_type":"code","execution_count":null,"id":"489ecf6b","metadata":{},"outputs":[],"source":["assistant = client.beta.assistants.update(\n","  assistant_id=assistant.id,\n","  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",")"]},{"cell_type":"markdown","id":"a754f345-fdc6-4e0d-b4d9-20e413155226","metadata":{},"source":["## Initiate interaction"]},{"cell_type":"markdown","id":"056705a1","metadata":{},"source":["### [Step 4: Create a thread - with File attachment](https://platform.openai.com/docs/assistants/tools/file-search/step-4-create-a-thread)\n","\n","You can also attach files as Message attachments on your thread. Doing so will create another vector_store associated with the thread, or, if there is already a vector store attached to this thread, attach the new files to the existing thread vector store. When you create a Run on this thread, the file search tool will query both the vector_store from your assistant and the vector_store on the thread.\n","\n","In this example, we have attached another pdf named [Intelizign Loan Policy.pdf](./data/Intelizign%20Loan%20Policy.pdf).\n"]},{"cell_type":"code","execution_count":null,"id":"1de26925","metadata":{},"outputs":[],"source":["# Upload the user provided file to OpenAI\n","message_file = client.files.create(\n","  file=open(\"data/Intelizign Loan Policy.pdf\", \"rb\"), purpose=\"assistants\"\n",")\n"," \n","# Create a thread and attach the file to the message\n","thread = client.beta.threads.create(\n","  messages=[\n","    {\n","      \"role\": \"user\",\n","      \"content\": \"what is the criteria to avail the loan amount?\",\n","      # Attach the new file to the message.\n","      \"attachments\": [\n","        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n","      ],\n","    }\n","  ]\n",")\n"," \n","# The thread now has a vector store with that file in its tool resources.\n","print(thread.tool_resources.file_search)"]},{"cell_type":"markdown","id":"c1edc9e3","metadata":{},"source":["### [Step 4: Create a thread - without File attachment using attached vector store](https://platform.openai.com/docs/assistants/tools/file-search/step-4-create-a-thread)"]},{"cell_type":"code","execution_count":null,"id":"731c22d7","metadata":{},"outputs":[],"source":["thread = client.beta.threads.create(\n","  messages=[\n","    {\n","      \"role\": \"user\",\n","      \"content\": \"Why do authors use the self-attention strategy in the paper?\"\n","    }\n","  ]\n",")\n","print(thread)"]},{"cell_type":"markdown","id":"1d9c9dca","metadata":{},"source":["### [Step 5: Create a run and check the output - Without Streaming](https://platform.openai.com/docs/assistants/tools/file-search/step-5-create-a-run-and-check-the-output)"]},{"cell_type":"code","execution_count":null,"id":"84418e43","metadata":{},"outputs":[],"source":["from openai import OpenAI\n"," \n","client = OpenAI()\n"," \n","run = client.beta.threads.runs.create_and_poll(\n","    thread_id=thread.id,\n","    assistant_id=assistant.id,\n","    #temperature=0,\n","    #top_p=1,\n","    #max_prompt_tokens=1000, # This can result in a failure if the retrieval cannot fit within the context window.\n","    #max_completion_tokens=500,\n","    # Overrides the instructions provided during assistant instantiation.\n","    #instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n","    #additional_instructions=\"Please address the user as chengaiah\",\n",")"]},{"cell_type":"markdown","id":"4da0bd2d","metadata":{},"source":["Check run status"]},{"cell_type":"code","execution_count":null,"id":"b509e822","metadata":{},"outputs":[],"source":["if run.status == 'completed': \n","  messages = client.beta.threads.messages.list(\n","    thread_id=thread.id\n","  )\n","  print(messages)\n","else:\n","  print(run.status)"]},{"cell_type":"markdown","id":"ea30ba13","metadata":{},"source":["Check Run steps"]},{"cell_type":"code","execution_count":null,"id":"b16b4fe2","metadata":{},"outputs":[],"source":["run_steps = client.beta.threads.runs.steps.list(\n","    thread_id=thread.id,\n","    run_id=run.id\n",")\n","\n","print(run_steps)"]},{"cell_type":"markdown","id":"dcea7c2a","metadata":{},"source":["### [Step 5: Create a run and check the output - With Streaming](https://platform.openai.com/docs/assistants/tools/file-search/step-5-create-a-run-and-check-the-output)"]},{"cell_type":"code","execution_count":null,"id":"5af88454","metadata":{},"outputs":[],"source":["from typing_extensions import override\n","from openai import AssistantEventHandler, OpenAI\n"," \n","client = OpenAI()\n"," \n","class EventHandler(AssistantEventHandler):\n","    @override\n","    def on_text_created(self, text) -> None:\n","        print(f\"\\nassistant > \", end=\"\", flush=True)\n","\n","    @override\n","    def on_tool_call_created(self, tool_call):\n","        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n","\n","    @override\n","    def on_message_done(self, message) -> None:\n","        # print a citation to the file searched\n","        message_content = message.content[0].text\n","        annotations = message_content.annotations\n","        citations = []\n","        for index, annotation in enumerate(annotations):\n","            message_content.value = message_content.value.replace(\n","                annotation.text, f\"[{index}]\"\n","            )\n","            if file_citation := getattr(annotation, \"file_citation\", None):\n","                cited_file = client.files.retrieve(file_citation.file_id)\n","                citations.append(f\"[{index}] {cited_file.filename}\")\n","\n","        print(message_content.value)\n","        print(\"\\n\".join(citations))\n","\n","\n","# Then, we use the stream SDK helper\n","# with the EventHandler class to create the Run\n","# and stream the response.\n","\n","with client.beta.threads.runs.stream(\n","    thread_id=thread.id,\n","    assistant_id=assistant.id,\n","    additional_instructions=\"Please address the user as chengaiah\",\n","    event_handler=EventHandler(),\n",") as stream:\n","    stream.until_done()"]},{"cell_type":"markdown","id":"bb6aedc8","metadata":{},"source":["## Utility actions"]},{"cell_type":"markdown","id":"8825be87","metadata":{},"source":["### Delete thread"]},{"cell_type":"code","execution_count":null,"id":"5d3a6f72","metadata":{},"outputs":[],"source":["from openai import OpenAI\n","client = OpenAI()\n","\n","response = client.beta.threads.delete(thread.id)\n","print(response)"]},{"cell_type":"markdown","id":"68ebc282","metadata":{},"source":["### Cancel All Runs associated to a thread"]},{"cell_type":"code","execution_count":null,"id":"758119b6","metadata":{},"outputs":[],"source":["from openai import OpenAI\n","client = OpenAI()\n","\n","runs = client.beta.threads.runs.list(\n","  thread.id\n",")\n","\n","for run in runs:\n","    print(f\"Cancelling run with id: {run.id}\")\n","    cancelled_run = client.beta.threads.runs.cancel(\n","      thread_id=thread.id,\n","      run_id=run.id\n","    )\n","    print(cancelled_run)"]},{"cell_type":"code","execution_count":null,"id":"2adf0fb0","metadata":{},"outputs":[],"source":[]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":5}
